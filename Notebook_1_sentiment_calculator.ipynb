{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***NOTEBOOK 1 : DATA COLLECTION AND SENTIMENT ANALYSIS***"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**DETAILS : COMPANIES STOCKS INFO AND DATA SCRAPING**\n",
        "\n",
        "In other to get the required dataset for sentiment analysis on financial stocks, we first of all install the **Finviz API** and the **YFinance API**.\n",
        "\n",
        "We use the finviz api to download the information of companies:\n",
        "|__ Ticker : This is the ticker symbol of the companies\n",
        "|__ Company Name : The Company name of the ticker\n",
        "|__ Sector : The Sector name in which the Company is a group of\n",
        "|__ Industry : The Indutry name in which the Company is a part of\n",
        "|__ Description : The Sector name in which the Company is a group of\n",
        "|__ Charts : This link redirects you to the chart image of the Company\n",
        "|__ Country : The Country name in which the Company is located\n",
        "|__ News : This part is a dataframe of a compact news on the Company with 3 columns (|__ date\t|__ title\t|__ link)\n",
        "\n",
        "We use the yfinance api to download the respective company stocks for the days in which we have a news value in other to compare the sentiment value and its effect on the stock prices. the data is downloaded in this a dataframe format (table name \"trade\") with the following column values: \n",
        "(\\_ date\t\\_open \t\\_ close  \\_ volume).  we then append the\t(|__ company_name\t|__ industry_name\t|__ sector_name) to the intitial trade dataframe downloaded in other to properly identify the values during sentiment analysis and model training\n",
        "\t"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.1: INSTALLING REQUIRED PACKAGES**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FamzdwY6Zwl2"
      },
      "source": [
        "**INSTALLING THE FINVIZ API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twP9-sUgnVrk",
        "outputId": "b53ec719-eee5-4c3a-af6e-6d51bbd9dcef"
      },
      "outputs": [],
      "source": [
        "!pip install finviz\n",
        "!pip install finvizfinance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s_5gq2KQaDZI"
      },
      "source": [
        "**INSTALLING THE YFINANCE API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Ds5W0026c4",
        "outputId": "6b7ad718-ad0d-4e43-efa4-1955a4e33a84"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.2 : IMPORTING LIBRARIES**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**IMPORTING NECCESSARY LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EvKayHH5myJ",
        "outputId": "82ed9c0e-ddd3-4cba-b94c-140d4ab2bf1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\liemu\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import neccesary libraries\n",
        "\n",
        "# \n",
        "import datetime\n",
        "\n",
        "# importing the finviz library\n",
        "import finviz\n",
        "from finviz.screener import Screener\n",
        "import finvizfinance\n",
        "\n",
        "# Importing Pandas Library for dataframe manipulations\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries used for Sentiment ANalysis\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# We use the warnings library to ignore Deprecated Warningd\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.3 : USING FINVIZ SCREENER TO SCRAPE COMPANIES CSV FILE**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MITmUQ5zasKu"
      },
      "source": [
        "**Reading the FINVIZ stocks data \"finviz_stocks_list.csv\"**\n",
        "\n",
        "We instantiate the Finviz Screener method, this action loads all the company names, ticker symbols, Sector, Industry, Country, Market Cap, PE, Price, Change, and Volume.\n",
        "We then save this info a csv format **\"finviz_stocks_list.csv\"** so we could use it later for other tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzymQSAum76G"
      },
      "outputs": [],
      "source": [
        "stock_list = Screener()\n",
        "stock_list.to_csv(\"finviz_stocks_list.csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.3.1 : CONVERTING THE FINVIZ CSV FILE TO DICTIONARY**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this **finviz_stocks_list.csv** file we just downloaded we are only interested in the (\"Ticker\", \"Company\", \"Sector\", \"Industry\", \"Country\") values, we then load this into a pandas dataframe **df**, and convert it to the form of a dictionary **result**, so we can easily attch other values to it with ease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ceve2wVz7H8H"
      },
      "outputs": [],
      "source": [
        "# Reading the FINVIZ stocks data \n",
        "df = pd.read_csv('./finviz_stocks_list.csv')\n",
        "df = df[[\"Ticker\", \"Company\", \"Sector\", \"Industry\", \"Country\"]]\n",
        "\n",
        "# Convert the DataFrame to a dictionary\n",
        "df_dict = df.to_dict(orient='records')\n",
        "# Create a new dictionary with Ticker as the key\n",
        "result = {\n",
        "          row['Ticker']: {'Company': row['Company'], 'Sector': row['Sector'],\n",
        "                         'Industry': row['Industry'], 'Country': row['Country']}\n",
        "          for row in df_dict}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "the result dict outputs in tgo following format:\n",
        "\n",
        "{\n",
        "  'AA': {'Company': 'Alcoa Corporation',\n",
        "  'Sector': 'Basic Materials',\n",
        "  'Industry': 'Aluminum',\n",
        "  'Country': 'USA'},\n",
        "\n",
        " 'AAAU': {'Company': 'Goldman Sachs Physical Gold ETF',\n",
        "  'Sector': 'Financial',\n",
        "  'Industry': 'Exchange Traded Fund',\n",
        "  'Country': 'USA'},\n",
        "  \n",
        "  ...}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.4 : USING FINVIZFINACE TO SCRAPE COMPANIES DESCRIPTION, CHARTS, AND NEWS**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FffSOBgOYnd2"
      },
      "source": [
        "**GETTING THE STOCKS DESCRIPTION, STOCK CHARTS, AND STOCK NEWS**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Next Step:**\n",
        "\n",
        "After step above, next is we use the finvizfinance methods to download additional company data. these methods are:\n",
        "\n",
        "**ticker_description** : This downloads the Company's description (what the company does) and we attach this value **\"description\"** to every ticker symbol in the result dictionary above.\n",
        "\n",
        "**ticker_charts** : This downloads the Company's stock chart (trading history chart) and we attach this value **\"charts\"** to every ticker symbol in the result dictionary above.\n",
        "\n",
        "**ticker_news** : This downloads the Company's news data from the finviz website (in compact format: around 100 news for each company) in a dataframe fromat and we attach this value **\"news\"** to every ticker symbol in the result dictionary above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "hIniy9IVqhwm",
        "outputId": "98eb7897-88a5-444f-bb05-e6273d67c37a"
      },
      "outputs": [],
      "source": [
        "# Getting company Description\n",
        "error_symbol = []\n",
        "for key in result:\n",
        "  try:\n",
        "    stock = finvizfinance(key)\n",
        "    # Stock description\n",
        "    description = stock.ticker_description()\n",
        "    result[key][\"description\"] = description\n",
        "    # Stock charts\n",
        "    result[key][\"charts\"] = stock.ticker_charts(urlonly=True)\n",
        "    # Stock News\n",
        "    news = stock.ticker_news()\n",
        "    news['Date'] = news['Date'].dt.date\n",
        "    # Get only today's date uncomment the code below\n",
        "    # today = datetime.datetime.now().date()\n",
        "    # news = news[news['Date'] == today]\n",
        "    result[key][\"news\"] = news\n",
        "  except:\n",
        "    error_symbol.append(key)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While downloading this datas (ticker_description, ticker_charts, and ticker_news), we might encounter some ticker symbol error, so in other to investigate this, we attach every error symbol to the **error_symbol** list so we could investigate the error further"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(error_symbol)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After confirming the ticker symbols in the error list at the finviz site, we found out that some of the ticker symbols are no longer valid, and has no datas on the site, while other ticker symbols experienced an error due to a network glitch. \n",
        "\n",
        "So in other to fix this, we have to iterate through the **error_symbol** list and re scrap their info once again, so we get all the data needed"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.4.1 : RE-USING FINVIZFINANCE TO SCRAPE COMPANIES DESCRIPTION, CHARTS, AND NEWS**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**DIDNT GET ALL THE COMPANIES INFORMATION EARLIER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting company Description\n",
        "tick = []\n",
        "# Iterating through the error_symbol list\n",
        "for key in error_symbol:\n",
        "  try:\n",
        "    stock = finvizfinance(key)\n",
        "    # Stock description\n",
        "    # This checks if the ticker key has a value for decription in its datas, and if it doesnt, then it downloads and attachs it, otherwise it skips\n",
        "    if 'description' not in result[key].keys():\n",
        "        description = stock.ticker_description()\n",
        "        result[key][\"description\"] = description\n",
        "    # Stock charts\n",
        "    # This checks if the ticker key has a value for charts in its datas, and if it doesnt, then it downloads and attachs it, otherwise it skips\n",
        "    if 'charts' not in result[key].keys():\n",
        "        result[key][\"charts\"] = stock.ticker_charts(urlonly=True)\n",
        "    # Stock News\n",
        "    # This checks if the ticker key has a value for news in its datas, and if it doesnt, then it downloads and attachs it, otherwise it skips\n",
        "    if 'news' not in result[key].keys():\n",
        "        news = stock.ticker_news()\n",
        "        news['Date'] = news['Date'].dt.date\n",
        "        # Get only today's date uncomment the code below\n",
        "        # today = datetime.datetime.now().date()\n",
        "        # news = news[news['Date'] == today]\n",
        "        result[key][\"news\"] = news\n",
        "  except:\n",
        "    tick.append(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(tick)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This action above downloads all the requested data for tickers that are valid in the error_symbol list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02eFhdkKfs6n",
        "outputId": "9c3bae3c-1e1a-4f28-eaa3-5c4bc49f53ea"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.5: GETTING THE NEWS SENTIMENT SCORES**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "In other to perform Sentiment analysis for each news in each ticker symbol, we will use the Natural Language ToolKit **NLTK** submodule **VADER**\n",
        "\n",
        "Our choice of the vader submodule is because we are dealing with an unlabelled text dataset, and this module calculates the positive/negative polarity and also the intensity of emotion (strength) which would all be helpful later on in this project.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting company Description\n",
        "# Iterating through all ticker symbols in the result dictionary\n",
        "for key in result:\n",
        "  # Check if the ticker symbol has a value for \"news\" in the result dictionary, and proceed if it does else skip\n",
        "  if 'news' in result[key].keys():\n",
        "    # Instantiating the vader SentimentIntensityAnalyzer\n",
        "    vader = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Create functions to calculate the compound, negative, positive, and neutral polarity value for each news headline\n",
        "    function = lambda title: vader.polarity_scores(title)['compound']\n",
        "    function1 = lambda title: vader.polarity_scores(title)['neg']\n",
        "    function2 = lambda title: vader.polarity_scores(title)['pos']\n",
        "    function3 = lambda title: vader.polarity_scores(title)['neu']\n",
        "    \n",
        "    # Stock sentiment calculation\n",
        "    # Applying the functions above to calcaalate the respective scores and attach them to the \"compound\", \"neg\", \"pos\", and \"neu\" value in the \"news\" datafame \n",
        "    result[key]['news']['compound'] = result[key]['news']['Title'].apply(function)\n",
        "    result[key]['news']['neg'] = result[key]['news']['Title'].apply(function1)\n",
        "    result[key]['news']['pos'] = result[key]['news']['Title'].apply(function2)\n",
        "    result[key]['news']['neu'] = result[key]['news']['Title'].apply(function3)\n",
        "\n",
        "    # Getting the sentiment score in ranges of (-10 to +10) for every headline in the \"news\" dataframe\n",
        "    # in other to achieve this we multiply the \"compound\" value for each headline by 10, and round it up to 0 decimal places\n",
        "    result[key]['news']['sentiment'] = result[key]['news']['compound'] * 10\n",
        "    result[key]['news']['sentiment'] = result[key]['news']['sentiment'].round()\n",
        "    # Lastly we convert the \"sentiment\" data type from float to integer\n",
        "    result[key]['news']['sentiment'] = result[key]['news']['sentiment'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have the news for each company and their corresponding sentiment scores"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.6: GETTING THE AVERAGE SENTIMENT SCORES BY DAYS AND ATTACHING IT TO THE \"comp\" VALUE IN EACH \"ticker\"**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "This would enable us to compare the effect of sentiment scores by days with the trading returns data to be downloaded from yfinance. the reason we are grouping the sentiment scores by days is beacuse the data we would be downloading at yfinance comes in **days** format not in **time**.\n",
        "\n",
        "Hence we group all the news scores by days, and take the weighted mean for the corresponding \"compound\", \"neg\", \"pos\", \"neu\" and \"sentiment\" value in the \"news\" datafame\n",
        "\n",
        "This would enable us to properly detect if there is a relationship between the values of sentiment scores and stock pricing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iterating through all ticker symbols in the result dictionary\n",
        "for key in result:\n",
        "  # Check if the ticker symbol has a value for \"news\" in the result dictionary, and proceed if it does else skip\n",
        "  if 'news' in result[key].keys():\n",
        "    # Attach the weighted mean values by days for the corresponding \"compound\", \"neg\", \"pos\", \"neu\" and \"sentiment\" value in the \"news\" datafame \n",
        "    # to the \"comp\" dataframe\n",
        "    result[key]['comp'] = result[key]['news'].groupby('Date').mean()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.7: GETTING THE START AND END DATE FROM THE 'comp' KEY IN EACH TICKER TO ENABLE US DOWNLOAD THE STOCKS PRICING DATA WITHIN THOSE RANGES**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "The next step is we extract the most recent date and the first date in the \"comp\" dataframe and attach the values to the \"latest_date\", and \"start_date\" respectively to enable us to download the stock prices for those dates ranges only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iterating through all ticker symbols in the result dictionary\n",
        "for key in result:\n",
        "   # Check if the ticker symbol has a value for \"comp\" in the result dictionary, and proceed if it does else skip\n",
        "  if 'comp' in result[key].keys():\n",
        "    # Extract the first date, convert it to date string format, and attach it to the \"start_date\" value of the \"ticker\" symbol in result dictionary\n",
        "    result[key]['start_date'] =  result[key]['comp'].index[0].strftime('%Y-%m-%d')\n",
        "    # Extract the most recent date, convert it to date string format, and attach it to the \"latest_date\" value of the \"ticker\" symbol in result dictionary\n",
        "    result[key]['latest_date'] =  result[key]['comp'].index[-1].strftime('%Y-%m-%d')\n",
        "    # Extract the most recent sentiment score, and attach it to the \"sentiment\" value of the ticker symbol in result dictionary \n",
        "    # which would be used later on while constructing the Knowledge Graph\n",
        "    result[key]['sentiment'] =  result[key]['comp']['sentiment'][-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confirm our work\n",
        "result['AA']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.8 : DOWNLOADING THE STOCKS PRICING DATA FROM YFINANCE**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "In this step we extract the (\"ticker\", \"start_date\", and \"latest_date\") for each ticker symbol in result dictionary and use the info to download the ['Open', 'Close', 'Volume'] values for each stock by dates and attach the trade dataframe to the \"trade\" key for each \"ticker\" key in result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "Hs0MX8l18ynD",
        "outputId": "5cc6dad9-15c9-4b9d-bef1-2b1d8d9d4a86"
      },
      "outputs": [],
      "source": [
        "# Importing the yfinance library\n",
        "import yfinance as yf\n",
        "# Iterating through all ticker symbols in the result dictionary\n",
        "for key in result:\n",
        "  # Check if the ticker symbol has a value for \"comp\" in the result dictionary, and proceed if it does else skip\n",
        "  if 'comp' in result[key].keys():\n",
        "    # Check if the ticker symbol already has a value for \"trade\" in the result dictionary, and proceed if it does not else skip\n",
        "    if 'trade' not in result[key].keys():\n",
        "      try:\n",
        "        # Downloading the \"Open\", \"Close\", and \"Volume\" value for each stock by days\n",
        "        data = yf.download(key, start= result[key]['start_date'], end=result[key]['latest_date'], progress=False)[['Open', 'Close', 'Volume']]\n",
        "        # Resetting the index to integers and not dates\n",
        "        data = data.reset_index()\n",
        "        # Attaching the trade dataframe to the \"trade\" key for each \"ticker\" symbol in the result dictionary\n",
        "        result[key]['trade'] = data\n",
        "      except:\n",
        "        print(f\"no data for {key} syymbol between the dates {result[key]['start_date']} - {result[key]['latest_date']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gJhPMvKjwSJ-",
        "outputId": "d3b61f5c-8a8c-4218-c0d8-9e28b45714c1"
      },
      "outputs": [],
      "source": [
        "result['AA']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.9: CHANGING THE DATA TYPE OF THE 'news', 'comp', AND 'trade' IN result DICTIONARY FROM DATAFRAMES TO DICTIONARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "S7BXi4G_wSjH",
        "outputId": "1fc7c93c-cc1a-4670-c442-8676a3639751"
      },
      "outputs": [],
      "source": [
        "# Iterating through all ticker symbols in the result dictionary\n",
        "for key in result:\n",
        "  # Check if the ticker symbol has a value for \"news\" in the result dictionary, and proceed if it does else skip\n",
        "  if 'news' in result[key].keys():\n",
        "    try:\n",
        "      # Converting the \"news\" of each ticcker in result dictionary from dataframe format to dictionary format\n",
        "      result[key]['news'] = result[key]['news'].to_dict(orient='records')\n",
        "    except:\n",
        "      print(f\"check if {key} news has been converted already to dict\")\n",
        "\n",
        "  # Check if the ticker symbol has a value for \"comp\" in the result dictionary, and proceed if it does else skip\n",
        "  if 'comp' in result[key].keys():\n",
        "    # Converting the \"comp\" of each ticcker in result dictionary from dataframe format to dictionary format\n",
        "    result[key]['comp'] = result[key]['comp'].reset_index().to_dict(orient='records')\n",
        "\n",
        "  # Check if the ticker symbol has a value for \"trade\" in the result dictionary, and proceed if it does else skip\n",
        "  if 'trade' in result[key].keys():\n",
        "    # Converting the \"trade\" of each ticcker in result dictionary from dataframe format to dictionary format\n",
        "    result[key]['trade'] = result[key]['trade'].to_dict(orient='records')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.9.1: CHANGING THE DATE TYPE FORMAT TO STRING**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Now we change the date format of datas in the \"news\", \"comp\", and \"trade\" dictionaries for each ticker symbol in result dictionary to a string date format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iterating through all ticker symbols in the result dictionary\n",
        "for key in result:\n",
        "    # Check if the ticker symbol has a value for \"news\" in the result dictionary, and proceed if it does else skip\n",
        "    if 'news' in result[key].keys():\n",
        "        # Iterate through the length of the news data\n",
        "        for i in range(len(result[key]['news'])):\n",
        "            try: \n",
        "                # Convert Date to Date string format\n",
        "                result[key]['news'][i]['Date'] = result[key]['news'][i]['Date'].strftime('%Y-%m-%d')\n",
        "            except:\n",
        "                f\"Already converted\"\n",
        "\n",
        "    # Check if the ticker symbol has a value for \"comp\" in the result dictionary, and proceed if it does else skip\n",
        "    if 'comp' in result[key].keys():\n",
        "        # Iterate through the length of the comp data\n",
        "        for i in range(len(result[key]['comp'])):\n",
        "            try: \n",
        "                # Convert Date to Date string format\n",
        "                result[key]['comp'][i]['Date'] = result[key]['comp'][i]['Date'].strftime('%Y-%m-%d')\n",
        "            except:\n",
        "                f\"Already converted\"\n",
        "\n",
        "    # Check if the ticker symbol has a value for \"trade\" in the result dictionary, and proceed if it does else skip\n",
        "    if 'trade' in result[key].keys():\n",
        "        # Iterate through the length of the trade data\n",
        "        for i in range(len(result[key]['trade'])):\n",
        "            # Convert Date to Date string format\n",
        "            result[key]['trade'][i]['Date'] = result[key]['trade'][i]['Date'].strftime('%Y-%m-%d')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.9.2: APPENDING THE COMPANY NAME, INDUSTRY, AND SECTOR OF EACH \"trade\" KEY**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Now we append the company name, industry name, sector name, and country name to each value in the \"trade\" dictionary for each ticker symbol, this would enable us to correctly identify the trade information a later task while concating the \"trade\" and \"comp\" dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iterating through all ticker symbols in the result dictionary\n",
        "for key in result:\n",
        "  # Check if the ticker symbol has a value for \"trade\" in the result dictionary, and proceed if it does else skip\n",
        "  if 'trade' in result[key].keys():\n",
        "    # Iterate through the length of the trade data\n",
        "    for i in range(len(result[key]['trade'])):\n",
        "      # Append the name of the Company to each value in the 'trade' list\n",
        "      result[key]['trade'][i]['Company'] = result[key]['Company']\n",
        "      # Append the name of the Industry to each value in the 'trade' list\n",
        "      result[key]['trade'][i]['Industry'] = result[key]['Industry']\n",
        "      # Append the name of the Sector to each value in the 'trade' list\n",
        "      result[key]['trade'][i]['Sector'] = result[key]['Sector']\n",
        "      # Append the name of the Country to each value in the 'trade' list\n",
        "      result[key]['trade'][i]['Country'] = result[key]['Country']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.9.3: APPENDING COMPANY, INDUSTRY, AND SECTOR NAME TO 'comp' KEY**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "We also append the company name, industry name, sector name, and country name to each value in the \"comp\" dictionary for each ticker symbol, this would enable us to correctly identify the trade information a later task while concating the \"trade\" and \"comp\" dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iterating through all ticker symbols in the result dictionary\n",
        "for key in result:\n",
        "  # Check if the ticker symbol has a value for \"comp\" in the result dictionary, and proceed if it does else skip\n",
        "  if 'comp' in result[key].keys():\n",
        "    # Iterate through the length of the comp data\n",
        "    for i in range(len(result[key]['comp'])):\n",
        "      # Append the name of the Company to each value in the 'comp' list\n",
        "      result[key]['comp'][i]['Company'] = result[key]['Company']\n",
        "      # Append the name of the Industry to each value in the 'comp' list\n",
        "      result[key]['comp'][i]['Industry'] = result[key]['Industry']\n",
        "      # Append the name of the Sector to each value in the 'comp' list\n",
        "      result[key]['comp'][i]['Sector'] = result[key]['Sector']\n",
        "      # Append the name of the Country to each value in the 'comp' list\n",
        "      result[key]['comp'][i]['Country'] = result[key]['Country']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1.10: SAVING THE DICTIONARY AS A PICKLE FILE**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Finally we can save our result dictionary data as a pickle file, so we could use it later on for other exploration tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeK4N2Hf8JGT"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# This will create a binary file called finviz.pickle and store all result dictionary info in the file\n",
        "with open(\"./finviz.pickle\", \"wb\") as f:\n",
        "    pickle.dump(result, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d2LKDNPdw5P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "787828705900a14b3ea64ed4a9d9c60d43e51464fce06f9d24d869b142aa00d8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
